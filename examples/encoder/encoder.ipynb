{"cells":[{"cell_type":"markdown","metadata":{},"source":["### Encoder\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import sys\n","\n","\n","def add_to_path(new_path: str):\n","    module_path = os.path.abspath(os.path.join(new_path))\n","    if module_path not in sys.path:\n","        sys.path.append(module_path)\n","\n","\n","is_colab = False\n","\n","if is_colab:\n","    !git clone https://github.com/pdkary/Karys.git\n","    !cd Karys && git fetch && git pull\n","    !cd Karys && pip install -r requirements.txt --quiet\n","    add_to_path('Karys/')\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    !cd Karys && pip install -r requirements.txt --quiet\n","else:\n","    add_to_path('../../')\n","    !cd ../../ && pip install -r requirements.txt --quiet\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Load the data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from data.configs.ImageDataConfig import ImageDataConfig\n","from data.wrappers.ImageDataWrapper import ImageDataWrapper\n","import numpy as np\n","\n","if is_colab:\n","    base_path = \"drive/MyDrive/Colab/Seefood/Fruit\"\n","else:\n","    base_path = \"../discriminator/test_input/Fruit\"\n","\n","image_config = ImageDataConfig(image_shape=(256,256,3),image_type=\".jpg\", preview_rows=4, preview_cols=2, load_n_percent=8)\n","\n","data_wrapper = ImageDataWrapper.load_from_labelled_directories(base_path + '/', image_config, validation_percentage=0.1)\n","classification_labels = list(set(data_wrapper.image_labels.values()))\n","\n","##Quick stats about loaded images\n","print(\"----------LOADED IMAGE CATEGORIES----------\")\n","print(classification_labels)\n","print(\"NUM IMAGES: \",len(data_wrapper.image_labels))\n","\n","print(\"----------LOADED IMAGE STATS----------\")\n","value_count_dict = {v:0 for v in set(data_wrapper.image_labels.values())}\n","for x in data_wrapper.image_labels.values():\n","    value_count_dict[x]+=1\n","print(value_count_dict)\n","print(\"Max: \",np.max(list(value_count_dict.values())), max(value_count_dict,key=value_count_dict.get))\n","print(\"Min: \",np.min(list(value_count_dict.values())), min(value_count_dict,key=value_count_dict.get))\n","print(\"Mean: \",np.mean(list(value_count_dict.values())))\n","print(\"Median: \",np.median(list(value_count_dict.values())))\n","print(\"Deviation: \",np.std(list(value_count_dict.values())))"]},{"cell_type":"markdown","metadata":{},"source":["### We want an encoder, and a classifier to identify the encodings"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from data.saved_models.SavedModelService import SavedModelService\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.losses import binary_crossentropy, MSE, CategoricalCrossentropy\n","\n","load_from_saved_models = False\n","\n","if is_colab:\n","  model_reference_path = \"drive/MyDrive/Colab/Seefood/models/model_ref.json\"\n","else:\n","  model_reference_path = \"./test_model_output/model_ref.json\"\n","\n","saved_model_service = SavedModelService(model_reference_path)"]},{"cell_type":"markdown","metadata":{},"source":["## Encoded Classifier"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from models.EncoderModel import EncoderModel\n","\n","from tensorflow.keras.layers import Conv2D, Dense, LeakyReLU, MaxPooling2D, Flatten, Activation, BatchNormalization\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.losses import CategoricalCrossentropy, Reduction\n","\n","ENCODED_DIM = 512\n","a = 0.08\n","\n","encoder_layers = [\n","    Conv2D(128,3), BatchNormalization(), LeakyReLU(a),\n","    Conv2D(128,3), BatchNormalization(), LeakyReLU(a),\n","    MaxPooling2D(),\n","    Conv2D(256,3), BatchNormalization(), LeakyReLU(a),\n","    Conv2D(256,3), BatchNormalization(), LeakyReLU(a),\n","    Conv2D(256,3), BatchNormalization(), LeakyReLU(a),\n","    MaxPooling2D(),\n","    Conv2D(512,3), BatchNormalization(), LeakyReLU(a),\n","    Conv2D(512,3), BatchNormalization(), LeakyReLU(a),\n","    Conv2D(512,3), BatchNormalization(), LeakyReLU(a),\n","    MaxPooling2D(),\n","    Flatten(),\n","    Dense(4096), Activation('tanh'),\n","    Dense(ENCODED_DIM), Activation('sigmoid'),\n","]\n","\n","encoder_optimizer = Adam(learning_rate=5e-5, decay=1e-9)\n","encoder_loss = CategoricalCrossentropy(reduction=Reduction.SUM)\n","\n","encoder = EncoderModel(image_config.image_shape, ENCODED_DIM, encoder_layers, encoder_optimizer, encoder_loss)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from models.ClassificationModel import ClassificationModel\n","\n","classifier_optimizer = Adam(learning_rate=5e-5)\n","classifier_loss = CategoricalCrossentropy(reduction=Reduction.SUM)\n","\n","classifier_layers = [\n","    Dense(ENCODED_DIM), Activation('tanh'),\n","    Dense(ENCODED_DIM), Activation('tanh'),\n","    Dense(ENCODED_DIM), Activation('tanh'),\n","    Dense(len(classification_labels)+1), Activation('softmax'),\n","]\n","\n","classifier = ClassificationModel(image_config.image_shape, classification_labels, ['invalid'], classifier_layers, classifier_optimizer, classifier_loss)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from models.EncodedClassificationModel import EncodedClassificationModel\n","\n","encoded_classifier = EncodedClassificationModel(encoder, classifier)\n","encoded_classifier.build()"]},{"cell_type":"markdown","metadata":{},"source":["## Training Loop"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from plotting.TrainPlotter import TrainPlotter\n","from trainers.EncoderTrainer import EncoderTrainer\n","\n","epochs=2000\n","trains_per_test=250\n","\n","train_columns = [\"Encoder Loss\", \"Encoded Classifier Loss\", \"Image Classifier Loss\", \"Test Encoder Loss\", \"Test Encoded Classifier Loss\", \"Test Image Classifier Loss\"]\n","loss_plot = TrainPlotter(moving_average_size=100, labels=train_columns)\n","trainer = EncoderTrainer(encoded_classifier, data_wrapper)\n","\n","if is_colab:\n","  image_output_path = \"drive/MyDrive/Colab/Seefood/output\"\n","else:\n","  image_output_path = \"./test_output\"\n","\n","e_test_loss, ec_test_loss, ic_test_loss = 0, 0, 0\n","for i in range(epochs):\n","  loss_plot.start_epoch()  \n","  e_loss, ec_loss, ic_loss = trainer.train(5, 1)\n","\n","  if i % trains_per_test == 0 and i != 0:\n","    e_test_loss, ec_test_loss, ic_test_loss = trainer.test(16,1)\n","    encoding_output_filename = image_output_path + \"/encoded-\" + str(i) + \".jpg\"\n","    classification_output_filename = image_output_path + \"/classified-\" + str(i) + \".jpg\"\n","\n","    data_wrapper.save_encoded_images(encoding_output_filename, trainer.most_recent_encoding, img_size=32)\n","    data_wrapper.save_classified_images(classification_output_filename, trainer.most_recent_classification, img_size=32)\n","      \n","  loss_plot.batch_update([e_loss, ec_loss, ic_loss, e_test_loss, ec_test_loss, ic_test_loss])\n","  loss_plot.log_epoch()"]},{"cell_type":"markdown","metadata":{},"source":["## Now we save the models"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from data.saved_models.SavedModelService import SavedModelService\n","\n","if is_colab:\n","  model_output_path = \"drive/MyDrive/Colab/Seefood/models\"\n","  model_reference_path = \"drive/MyDrive/Colab/Seefood/models/model_ref.json\"\n","else:\n","  model_output_path = \"./test_model_output\"\n","  model_reference_path = \"./test_model_output/model_ref.json\"\n","\n","saved_model_service = SavedModelService(model_reference_path)\n","saved_model_service.save_model(\"FruitEncoder\", model_output_path, encoded_classifier.encoder)\n","saved_model_service.save_model(\"EncodedFruitClassifier\", model_output_path, encoded_classifier.classifier)"]}],"metadata":{"interpreter":{"hash":"63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"},"kernelspec":{"display_name":"Python 3.9.4 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.4"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
