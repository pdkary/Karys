{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -andas (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -andas (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -andas (c:\\python39\\lib\\site-packages)\n",
      "  WARNING: Failed to write executable - trying to use .deleteme logic\n",
      "ERROR: Could not install packages due to an OSError: [WinError 2] The system cannot find the file specified: 'c:\\\\python39\\\\Scripts\\\\jupyter.exe' -> 'c:\\\\python39\\\\Scripts\\\\jupyter.exe.deleteme'\n",
      "\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -andas (c:\\python39\\lib\\site-packages)\n",
      "WARNING: You are using pip version 21.1.3; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the 'c:\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "def add_to_path(new_path: str):\n",
    "    module_path = os.path.abspath(os.path.join(new_path))\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "\n",
    "is_colab = False\n",
    "\n",
    "if is_colab:\n",
    "    !git clone https://github.com/pdkary/Karys.git\n",
    "    !cd Karys && git fetch && git pull\n",
    "    !cd Karys && pip install -r requirements.txt --quiet\n",
    "    add_to_path(\"Karys/\")\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "    !cd Karys && pip install -r requirements.txt --quiet\n",
    "else:\n",
    "    add_to_path(\"../../\")\n",
    "    !cd ../../ && pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n",
      "sentence in:\n",
      " cash get your friends the car the spot the reservation then you're standing around whatta you do you go we gotta be getting back once you're out you wanna get (30,)\n",
      "\n",
      "sentence out:\n",
      " back you wanna go to sleep you wanna get up (10,)\n"
     ]
    }
   ],
   "source": [
    "from data.configs.TextDataConfig import TextDataConfig\n",
    "from data.wrappers.TextDataWrapper import TextDataWrapper\n",
    "\n",
    "if is_colab:\n",
    "    file_input = \"drive/MyDrive/Colab/Language/seinfeld_corpus.txt\"\n",
    "else:\n",
    "    file_input = \"./test_input/corpus.txt\"\n",
    "\n",
    "vocab_size = 10000\n",
    "sentence_length = 30\n",
    "output_length = 10\n",
    "\n",
    "text_config = TextDataConfig(vocab_size, sentence_length, output_length)\n",
    "text_data_wrapper = TextDataWrapper.load_from_file(file_input, text_config)\n",
    "text_data_wrapper.show_sentence_n(135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 30)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 30, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 30, 128)           131584    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10000)             10250000  \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 10000)             0         \n",
      "=================================================================\n",
      "Total params: 12,712,720\n",
      "Trainable params: 12,712,720\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 10)]              0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                704       \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "re_lu_5 (ReLU)               (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "re_lu_6 (ReLU)               (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 2050      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 1,725,890\n",
      "Trainable params: 1,725,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.functional.Functional at 0x23d95b61cd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from models.ModelWrapper import ModelWrapper\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU, ReLU, Activation, LSTM, Embedding, Softmax, Activation\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.losses import MSE, MSLE, binary_crossentropy, categorical_crossentropy\n",
    "\n",
    "LR = 4e-5\n",
    "\n",
    "## Generator\n",
    "a = 0.08\n",
    "g_layers = [\n",
    "    ##128 represents vector space size of the vocabulary\n",
    "    Embedding(text_config.vocab_size, 128, input_length=sentence_length),\n",
    "    LSTM(128, return_sequences=True),\n",
    "    LSTM(256),\n",
    "    Dense(512), ReLU(),\n",
    "    Dense(1024), ReLU(),\n",
    "    Dense(text_config.vocab_size), Softmax()]\n",
    "\n",
    "g_optimizer = Adam(learning_rate=LR)\n",
    "g_loss = categorical_crossentropy\n",
    "#should take in input shape, and give out output shape\n",
    "text_generator_model = ModelWrapper(text_config.input_shape, text_config.output_shape, g_layers, g_optimizer, g_loss, flatten_input=False)\n",
    "text_generator_model.build()\n",
    "\n",
    "## Discriminator\n",
    "d_layers = [\n",
    "    Dense(64), ReLU(),\n",
    "    Dense(256), ReLU(),\n",
    "    Dense(512), ReLU(),\n",
    "    Dense(1024), ReLU(),\n",
    "    Dense(1024), ReLU(),\n",
    "    Dense(2), Activation(\"softmax\")\n",
    "]\n",
    "\n",
    "d_optimizer = Adam(learning_rate=LR)\n",
    "d_loss = categorical_crossentropy\n",
    "text_discriminator_model = ModelWrapper(text_config.label_shape,[2],d_layers,d_optimizer,d_loss)\n",
    "text_discriminator_model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-ee4cffbc79b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;31m# loss_plot.start_epoch()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mgen_train_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisc_train_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext_trainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatches_per_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[0moutput_fig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_plot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_trainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_histogram\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Dev\\Karys\\trainers\\TextTrainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, batch_size, num_batches)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m                 \u001b[0mgen_grads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_tape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m                 \u001b[0mdisc_grads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdisc_tape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdisc_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen_grads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdisc_grads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1072\u001b[0m                           for x in nest.flatten(output_gradients)]\n\u001b[0;32m   1073\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1074\u001b[1;33m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[0;32m   1075\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1076\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[0;32m     72\u001b[0m       \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_ones\u001b[1;34m(shape, dtype)\u001b[0m\n\u001b[0;32m    693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_ones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 695\u001b[1;33m   \u001b[0mas_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    696\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mas_dtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    697\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from trainers.TextTrainer import TextTrainer\n",
    "from plotting.TrainPlotter import TrainPlotter\n",
    "from plotting.LiveHistogramPlotter import LiveHistogramPlotter\n",
    "import json\n",
    "\n",
    "if is_colab:\n",
    "    file_output = \"drive/MyDrive/Colab/Language/output/seinfeld.txt\"\n",
    "else:\n",
    "    file_output = \"./test_output/output.txt\"\n",
    "\n",
    "train_columns = [\"Train Gen Loss\", \"Train Disc Loss\", \"Test Gen Loss\", \"Test Disc Loss\"]\n",
    "output_plot = LiveHistogramPlotter()\n",
    "# loss_plot = TrainPlotter(moving_average_size=100,labels=train_columns)\n",
    "\n",
    "\n",
    "epochs=1000\n",
    "batch_size = 3\n",
    "trains_per_test=4\n",
    "batches_per_train = 1\n",
    "\n",
    "text_trainer = TextTrainer(text_generator_model, text_discriminator_model, text_data_wrapper)\n",
    "\n",
    "gen_test_loss, disc_test_loss = 0,0\n",
    "for i in range(epochs):\n",
    "    # loss_plot.start_epoch()\n",
    "    gen_train_loss, disc_train_loss = text_trainer.train(batch_size, batches_per_train)\n",
    "    output_fig = output_plot.update(text_trainer.output_histogram)\n",
    "\n",
    "    if i % trains_per_test == 0 and i != 0:\n",
    "        gen_test_loss, disc_test_loss = text_trainer.test(5, 1)\n",
    "        ins = text_data_wrapper.translate_sentences(text_trainer.most_recent_inputs)\n",
    "        outs = text_data_wrapper.translate_sentences(text_trainer.most_recent_outputs)\n",
    "        \n",
    "        get_inout_text = lambda x: \"\\n\".join([\"INPUT: \", ins[x], \" OUTPUT: \", outs[x]])\n",
    "        test_output_text = \"\\n\\n\".join([get_inout_text(x) for x in range(len(ins))])\n",
    "        with open(file_output,'w+') as f:\n",
    "            f.write(test_output_text)\n",
    "\n",
    "    # loss_plot.batch_update([gen_train_loss, disc_train_loss, gen_test_loss, disc_test_loss])\n",
    "    # loss_plot.log_epoch()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
