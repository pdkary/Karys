{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "def add_to_path(new_path: str):\n",
    "    module_path = os.path.abspath(os.path.join(new_path))\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "\n",
    "is_colab = False\n",
    "\n",
    "if is_colab:\n",
    "    !git clone https://github.com/pdkary/Karys.git\n",
    "    !cd Karys && git fetch && git pull\n",
    "    !cd Karys && pip install -r requirements.txt --quiet\n",
    "    add_to_path(\"Karys/\")\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "    !cd Karys && pip install -r requirements.txt --quiet\n",
    "else:\n",
    "    add_to_path(\"../../\")\n",
    "    !cd ../../ && pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.configs.TextDataConfig import TextDataConfig\n",
    "from data.wrappers.TextDataWrapper import TextDataWrapper\n",
    "\n",
    "if is_colab:\n",
    "    file_input = \"drive/MyDrive/Colab/Language/seinfeld_corpus.txt\"\n",
    "else:\n",
    "    file_input = \"./test_input/corpus.txt\"\n",
    "\n",
    "word_dimensionality = 50\n",
    "\n",
    "vocab_size = 2000\n",
    "sentence_length = 5\n",
    "\n",
    "text_config = TextDataConfig(vocab_size, sentence_length)\n",
    "text_data_wrapper = TextDataWrapper.load_from_file(file_input, text_config)\n",
    "text_data_wrapper.show_sentence_n(135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from models.ModelWrapper import ModelWrapper\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU, ReLU, Activation, LSTM, Embedding, Softmax\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.losses import MSE, MSLE, binary_crossentropy, categorical_crossentropy\n",
    "\n",
    "text_feature_size = 100\n",
    "\n",
    "a = 0.08\n",
    "glayers = [\n",
    "    Embedding(vocab_size,word_dimensionality,input_length=sentence_length),\n",
    "    LSTM(100, return_sequences=True),\n",
    "    LSTM(100),\n",
    "    Dense(100,activation='relu'),\n",
    "    Dense(vocab_size), Softmax()]\n",
    "goptimizer = RMSprop(learning_rate=5e-3)\n",
    "gloss = categorical_crossentropy\n",
    "#should take in input shape, and give out output shape\n",
    "text_generator_model = ModelWrapper(text_config.input_shape, text_config.output_shape, glayers, goptimizer, gloss, flatten_input=False)\n",
    "text_generator_model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainers.TextTrainer import TextTrainer\n",
    "from plotting.TrainPlotter import TrainPlotter\n",
    "import json\n",
    "\n",
    "if is_colab:\n",
    "    file_output = \"drive/MyDrive/Colab/Language/output/seinfeld.json\"\n",
    "else:\n",
    "    file_output = \"./test_output/output.json\"\n",
    "\n",
    "train_columns = [\"Train Loss\",\"Test Loss\"]\n",
    "loss_plot = TrainPlotter(moving_average_size=100,labels=train_columns)\n",
    "\n",
    "epochs=1000\n",
    "batch_size = 5\n",
    "trains_per_test=10\n",
    "batches_per_train = 10\n",
    "\n",
    "text_trainer = TextTrainer(text_generator_model, text_data_wrapper)\n",
    "test_phrases = [\n",
    "    \"jerry can i borrow your\",\n",
    "    \"i can never catch a\",\n",
    "    \"elaine and jerry are a\",\n",
    "    \"kramer what are you doing\",\n",
    "    \"george will never get a\"\n",
    "]\n",
    "\n",
    "seed_phrase = \"jerry can i borrow your\"\n",
    "\n",
    "test_loss = 0\n",
    "for i in range(epochs):\n",
    "    loss_plot.start_epoch()\n",
    "    train_loss = text_trainer.train(batch_size, batches_per_train)\n",
    "\n",
    "    if i % trains_per_test == 0 and i != 0:\n",
    "        test_loss = text_trainer.test(25, 1)\n",
    "        output = {}\n",
    "        for s in test_phrases:\n",
    "            output[s] = text_trainer.propogate_from_phrase(s, 5)\n",
    "\n",
    "        with open(file_output,'w+') as f:\n",
    "            json.dump(output,f)\n",
    "\n",
    "    loss_plot.batch_update([train_loss, test_loss])\n",
    "    loss_plot.log_epoch()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
