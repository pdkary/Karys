{"cells":[{"cell_type":"markdown","metadata":{},"source":["### Autoencoder_gan"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import sys\n","\n","def add_to_path(new_path: str):\n","    module_path = os.path.abspath(os.path.join(new_path))\n","    if module_path not in sys.path:\n","        sys.path.append(module_path)\n","\n","is_colab = False\n","\n","if is_colab:\n","    !git clone https://github.com/pdkary/Karys.git\n","    !cd Karys && git fetch && git pull\n","    !cd Karys && pip install -r requirements.txt --quiet --user\n","    add_to_path('Karys/')\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    !cd Karys && pip install -r requirements.txt --quiet --user\n","else:\n","    add_to_path('../../')\n","    !pip install -r ../../requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from data.configs.ImageDataConfig import ImageDataConfig\n","from data.wrappers.ImageDataWrapper import ImageDataWrapper\n","import numpy as np\n","\n","if is_colab:\n","    base_path = \"drive/MyDrive/Colab/Seefood/Fruit\"\n","else:\n","    base_path = \"../discriminator/test_input/Fruit\"\n","\n","image_config = ImageDataConfig(image_shape=(64,64,3),image_type=\".jpg\", preview_rows=4, preview_cols=2, load_n_percent=2)\n","\n","only_some_fruit = ['Watermelon', 'Peach', 'Pomegranate', 'Pineapple', 'Orange', 'Banana', 'Strawberry', 'Apple Braeburn', 'Lemon', 'Raspberry', 'Avocado', 'Pepper Green', 'Cherry', 'Limes', 'Cantaloupe', 'Corn', 'Pear']\n","data_wrapper = ImageDataWrapper.load_from_labelled_directories(base_path + '/', image_config, validation_percentage=0.1, use_dirs=only_some_fruit)\n","classification_labels = list(set(data_wrapper.image_labels.values()))\n","\n","##Quick stats about loaded images\n","print(\"----------LOADED IMAGE CATEGORIES----------\")\n","print(classification_labels)\n","print(\"NUM IMAGES: \",len(data_wrapper.image_labels))\n","\n","print(\"----------LOADED IMAGE STATS----------\")\n","value_count_dict = {v:0 for v in set(data_wrapper.image_labels.values())}\n","for x in data_wrapper.image_labels.values():\n","    value_count_dict[x]+=1\n","print(value_count_dict)\n","print(\"Max: \",np.max(list(value_count_dict.values())), max(value_count_dict,key=value_count_dict.get))\n","print(\"Min: \",np.min(list(value_count_dict.values())), min(value_count_dict,key=value_count_dict.get))\n","print(\"Mean: \",np.mean(list(value_count_dict.values())))\n","print(\"Median: \",np.median(list(value_count_dict.values())))\n","print(\"Deviation: \",np.std(list(value_count_dict.values())))"]},{"cell_type":"markdown","metadata":{},"source":["#### We're going to load a previous model from the encoder example... run it yourself if you want one"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from data.saved_models.SavedModelService import SavedModelService\n","from models.EncoderModel import EncoderModel\n","from models.ClassificationModel import ClassificationModel\n","from models.EncodedClassificationModel import EncodedClassificationModel\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.losses import CategoricalCrossentropy, Reduction\n","\n","if is_colab:\n","  model_output_path = \"drive/MyDrive/Colab/Seefood/models\"\n","  model_reference_path = \"drive/MyDrive/Colab/Seefood/models/model_ref.json\"\n","else:\n","  model_output_path = \"./test_model_output\"\n","  model_reference_path = \"../encoder/test_model_output/model_ref.json\"\n","\n","saved_model_service = SavedModelService(model_reference_path)\n","\n","encoder_optimizer = Adam(learning_rate=5e-5, decay=1e-9)\n","classifier_optimizer = Adam(learning_rate=5e-5, decay=1e-9)\n","encoder_loss = CategoricalCrossentropy(reduction=Reduction.SUM)\n","classifier_loss = CategoricalCrossentropy(from_logits=True, reduction=Reduction.SUM)\n","\n","encoder_model: EncoderModel = saved_model_service.load_model_by_name(\"FruitEncoder\", EncoderModel, encoder_optimizer, encoder_loss)\n","classification_model: ClassificationModel = saved_model_service.load_model_by_name(\"EncodedFruitClassifier\", ClassificationModel, classification_labels, optimizer=classifier_optimizer, loss=classifier_loss)\n","\n","encoded_classifier: EncodedClassificationModel = EncodedClassificationModel(encoder_model, classification_model)\n","encoded_classifier.build()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from models.GenerationModel import GenerationModel\n","from tensorflow.keras.layers import Conv2D, Dense, LeakyReLU, Activation, Flatten, Reshape, UpSampling2D, BatchNormalization\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.losses import CategoricalCrossentropy, Reduction\n","from tensorflow_addons.layers import InstanceNormalization\n","\n","ENCODED_DIM = encoded_classifier.encoder.output_shape[-1]\n","\n","a = 0.08\n","gen_layers = [\n","    Dense(512), Activation('relu'),\n","    Dense(4096), Activation('relu'),\n","    Reshape((2,2,1024)),\n","    UpSampling2D(),\n","    Conv2D(1024,3,padding=\"same\"), BatchNormalization(), LeakyReLU(a),\n","    Conv2D(1024,3,padding=\"same\"), BatchNormalization(), LeakyReLU(a),\n","    Conv2D(1024,3,padding=\"same\"), BatchNormalization(), LeakyReLU(a),\n","    UpSampling2D(),\n","    Conv2D(256,3,padding=\"same\"), BatchNormalization(), LeakyReLU(a),\n","    Conv2D(256,3,padding=\"same\"), BatchNormalization(), LeakyReLU(a),\n","    Conv2D(256,3,padding=\"same\"), BatchNormalization(), LeakyReLU(a),\n","    UpSampling2D(),\n","    Conv2D(64,3,padding=\"same\"), BatchNormalization(), LeakyReLU(a),\n","    Conv2D(64,3,padding=\"same\"), BatchNormalization(), LeakyReLU(a),\n","    Conv2D(64,3,padding=\"same\"), BatchNormalization(), LeakyReLU(a),\n","    UpSampling2D(),\n","    Conv2D(32,3,padding=\"same\"), BatchNormalization(), LeakyReLU(a),\n","    Conv2D(32,3,padding=\"same\"), BatchNormalization(), LeakyReLU(a),\n","    Conv2D(32,3,padding=\"same\"), BatchNormalization(), LeakyReLU(a),\n","    UpSampling2D(),\n","    Conv2D(16,3,padding=\"same\"), BatchNormalization(), LeakyReLU(a),\n","    Conv2D(16,3,padding=\"same\"), BatchNormalization(), LeakyReLU(a),\n","    Conv2D(3,3,padding=\"same\"), Activation('sigmoid'),\n","]\n","\n","optimizer = Adam(learning_rate=5e-4)\n","loss = CategoricalCrossentropy(from_logits=True, reduction=Reduction.SUM)\n","generator = GenerationModel(ENCODED_DIM, image_config.image_shape,gen_layers,optimizer,loss)\n","generator.build()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from plotting.TrainPlotter import TrainPlotter\n","from trainers.AutoEncoderTrainer import AutoEncoderTrainer\n","\n","epochs=11\n","trains_per_test=5\n","\n","train_columns = [\"Encoder Loss\", \"Classifier Loss\", \"Generator Loss\", \"Test Encoder Loss\", \"Test Classifier Loss\", \"Test Generator Loss\"]\n","loss_plot = TrainPlotter(moving_average_size=100, labels=train_columns)\n","trainer = AutoEncoderTrainer(encoded_classifier, generator, data_wrapper)\n","\n","if is_colab:\n","  image_output_path = \"drive/MyDrive/Colab/Seefood/output\"\n","else:\n","  image_output_path = \"./test_output\"\n","\n","e_test_loss, c_test_loss, g_test_loss = 0, 0, 0\n","for i in range(epochs):\n","  loss_plot.start_epoch()  \n","  e_loss, c_loss, g_loss = trainer.train(5, 1)\n","\n","  if i % trains_per_test == 0 and i != 0:\n","    e_test_loss, c_test_loss, g_test_loss = trainer.test(16,1)\n","    encoding_real_filename = image_output_path + \"/encoded-real-\" + str(i) + \".jpg\"\n","    encoding_gen_filename = image_output_path + \"/encoded-gen-\" + str(i) + \".jpg\"\n","    classification_real_filename = image_output_path + \"/classified-real-\" + str(i) + \".jpg\"\n","    classification_gen_filename = image_output_path + \"/classified-gen-\" + str(i) + \".jpg\"\n","\n","\n","    data_wrapper.save_generated_images(encoding_real_filename, trainer.most_recent_generated)\n","    data_wrapper.save_encoded_images(encoding_real_filename, trainer.most_recent_real_encoding, img_size=32)\n","    data_wrapper.save_encoded_images(encoding_gen_filename, trainer.most_recent_gen_encoding, img_size=32)\n","    data_wrapper.save_classified_images(classification_real_filename, trainer.most_recent_real_classification, img_size=32)\n","    data_wrapper.save_classified_images(classification_gen_filename, trainer.most_recent_gen_classification, img_size=32)\n","      \n","  loss_plot.batch_update([e_loss, c_loss, g_loss, e_test_loss, c_test_loss, g_test_loss])\n","  loss_plot.log_epoch()"]}],"metadata":{"interpreter":{"hash":"63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"},"kernelspec":{"display_name":"Python 3.9.4 64-bit","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.9.4"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
